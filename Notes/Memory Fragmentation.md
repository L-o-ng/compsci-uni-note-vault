#notes 

**External Fragmentation** is memory space that is able to satisfy a request but is not [[Contiguous Memory Allocation|contiguous]].
**Internal Fragmentation** is memory that is allocated successfully but may be slightly larger than the requested amount of memory. This size difference is due to the memory being stored as blocks divisible by powers of 2.
## 50% Rule
First-fit analysis reveals that given $N$ blocks allocated, $\frac{N}{2}$ blocks are lost due to fragmentation. $\frac{1}{3}$ may be *unusable*. 
The OS can use **compaction** to reduce external fragmentation - shuffle memory contents to place all free memory together in one large block.
## Paging
The physical address space of a process can be non-contiguous; a process is allocated physical memory whenever the latter is available. This:
+ Avoids external fragmentation;
+ Avoids varying-sized memory chunks.
Physical memory is divided into fixed-size blocks called **frames**. Typically the size is a power of 2 between 512 and 8192 bytes.
Logical memory is divided into blocks of the same size called **pages**.

To run a program of $n$ pages, the OS finds $n$ free frames to load the program into. This process is called **paging**. A **page table** is set up to help manage the mapping of logical to physical addresses using an address translation.
This still has internal fragmentation.
### Address Translation Scheme
The logical memory address generated by the CPU is divided into:
+ **Page Number** ($p$) - Used as an index into a page table which contains the base address of each page in physical memory;
+ **Page Offset** ($d$) - This is combined with the base address to define the physical memory address that is sent to the memory unit.
So, given logical address space $2^{m}$ and page size $2^{n}$:
### Paging Hardware
The MMU translates a logical address to a physical address by the following process:
1) Extract the page number $p$ and use it as an index into the page table.
2) Extract the corresponding frame number $f$ from the page table.
3) Replace $p$ in the logical address with $f$.
![[Paging Hardware Flowchart.png]]
### Implementation
A page table can be implemented in many ways. One is to keep the page table in main memory, and a page-table base register (PTBR) points to it. In this scheme, every data/instruction access requires two memory accesses - one for the page table and one for the actual read. This can be fixed by using a special fast-lookup hardware cache called associative memory/translation look-aside buffers.
#### Translation Look-Aside Buffer (TLB)
![[Translation Look-Aside Buffer.png]]
When a logical address is generated by the CPU, the MMU first checks if its page number is present in the TLB:
+ If it is found, its frame number is immediately available and used to access memory;
+ If it is not found (a **TLB Miss**), a memory reference to the page table must be made;
	+ A frame number is then obtained;
	+ The page number and frame number is added to the TLB so repeat access is faster.
+ If the TLB is full, an existing entry is selected for replacement.
#### Effective Access Time (EAT)
We call the percentage of times that a page number is found in the associative registers - the ratio related to the number of associative registers - the **hit ratio**, $\alpha$.
We define:
$$
\text{EAT}=(\alpha \times\text{memory access time})+((1-\alpha)\times(2\times\text{memory access time}))
$$
